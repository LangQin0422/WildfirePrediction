{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Machine Learning Examples\n",
                "### Lang Qin\n",
                "- This demonstration will cover 3 machine learning algorithms: **RidgeClassifier, RandomForestClassifier, KNeighborsClassifier.**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Data Preparation\n",
                "Suppose we are going to predict the magnitude of the wildfire based on climate factors, and there is a data set containing a large number of recorded wildfire cases in the U.S.. \n",
                "\n",
                "\n",
                "Before we do real stuff on algorithms, we must prepare our data. Let's first take a look at our data set. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "source": [
                "import pandas as pd\n",
                "\n",
                "file_directory = '/Users/langqin/Documents/Microsoft Intern/Task 1/FW_Veg_Rem_Combined.csv'\n",
                "\n",
                "raw = pd.read_csv(file_directory)\n",
                "# preview the top 5 rows of the dataset\n",
                "raw.head()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   Unnamed: 0  Unnamed: 0.1 fire_name  fire_size fire_size_class  \\\n",
                            "0           0             0       NaN       10.0               C   \n",
                            "1           1             1       NaN        3.0               B   \n",
                            "2           2             2       NaN       60.0               C   \n",
                            "3           3             3    WNA  1        1.0               B   \n",
                            "4           4             4       NaN        2.0               B   \n",
                            "\n",
                            "    stat_cause_descr   latitude   longitude state disc_clean_date  ...  \\\n",
                            "0  Missing/Undefined  18.105072  -66.753044    PR       2/11/2007  ...   \n",
                            "1              Arson  35.038330  -87.610000    TN      12/11/2006  ...   \n",
                            "2              Arson  34.947800  -88.722500    MS       2/29/2004  ...   \n",
                            "3     Debris Burning  39.641400 -119.308300    NV        6/6/2005  ...   \n",
                            "4      Miscellaneous  30.700600  -90.591400    LA       9/22/1999  ...   \n",
                            "\n",
                            "  Wind_cont Hum_pre_30 Hum_pre_15  Hum_pre_7   Hum_cont Prec_pre_30  \\\n",
                            "0  3.250413  78.216590  76.793750  76.381579  78.724370         0.0   \n",
                            "1  2.122320  70.840000  65.858911  55.505882  81.682678        59.8   \n",
                            "2  3.369050  75.531629  75.868613  76.812834  65.063800       168.8   \n",
                            "3  0.000000  44.778429  37.140811  35.353846   0.000000        10.4   \n",
                            "4 -1.000000  -1.000000  -1.000000  -1.000000  -1.000000        -1.0   \n",
                            "\n",
                            "   Prec_pre_15 Prec_pre_7 Prec_cont  remoteness  \n",
                            "0          0.0        0.0       0.0    0.017923  \n",
                            "1          8.4        0.0      86.8    0.184355  \n",
                            "2         42.2       18.1     124.5    0.194544  \n",
                            "3          7.2        0.0       0.0    0.487447  \n",
                            "4         -1.0       -1.0      -1.0    0.214633  \n",
                            "\n",
                            "[5 rows x 43 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Unnamed: 0</th>\n",
                            "      <th>Unnamed: 0.1</th>\n",
                            "      <th>fire_name</th>\n",
                            "      <th>fire_size</th>\n",
                            "      <th>fire_size_class</th>\n",
                            "      <th>stat_cause_descr</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>state</th>\n",
                            "      <th>disc_clean_date</th>\n",
                            "      <th>...</th>\n",
                            "      <th>Wind_cont</th>\n",
                            "      <th>Hum_pre_30</th>\n",
                            "      <th>Hum_pre_15</th>\n",
                            "      <th>Hum_pre_7</th>\n",
                            "      <th>Hum_cont</th>\n",
                            "      <th>Prec_pre_30</th>\n",
                            "      <th>Prec_pre_15</th>\n",
                            "      <th>Prec_pre_7</th>\n",
                            "      <th>Prec_cont</th>\n",
                            "      <th>remoteness</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>10.0</td>\n",
                            "      <td>C</td>\n",
                            "      <td>Missing/Undefined</td>\n",
                            "      <td>18.105072</td>\n",
                            "      <td>-66.753044</td>\n",
                            "      <td>PR</td>\n",
                            "      <td>2/11/2007</td>\n",
                            "      <td>...</td>\n",
                            "      <td>3.250413</td>\n",
                            "      <td>78.216590</td>\n",
                            "      <td>76.793750</td>\n",
                            "      <td>76.381579</td>\n",
                            "      <td>78.724370</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.017923</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>Arson</td>\n",
                            "      <td>35.038330</td>\n",
                            "      <td>-87.610000</td>\n",
                            "      <td>TN</td>\n",
                            "      <td>12/11/2006</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2.122320</td>\n",
                            "      <td>70.840000</td>\n",
                            "      <td>65.858911</td>\n",
                            "      <td>55.505882</td>\n",
                            "      <td>81.682678</td>\n",
                            "      <td>59.8</td>\n",
                            "      <td>8.4</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>86.8</td>\n",
                            "      <td>0.184355</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2</td>\n",
                            "      <td>2</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>60.0</td>\n",
                            "      <td>C</td>\n",
                            "      <td>Arson</td>\n",
                            "      <td>34.947800</td>\n",
                            "      <td>-88.722500</td>\n",
                            "      <td>MS</td>\n",
                            "      <td>2/29/2004</td>\n",
                            "      <td>...</td>\n",
                            "      <td>3.369050</td>\n",
                            "      <td>75.531629</td>\n",
                            "      <td>75.868613</td>\n",
                            "      <td>76.812834</td>\n",
                            "      <td>65.063800</td>\n",
                            "      <td>168.8</td>\n",
                            "      <td>42.2</td>\n",
                            "      <td>18.1</td>\n",
                            "      <td>124.5</td>\n",
                            "      <td>0.194544</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>3</td>\n",
                            "      <td>3</td>\n",
                            "      <td>WNA  1</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>Debris Burning</td>\n",
                            "      <td>39.641400</td>\n",
                            "      <td>-119.308300</td>\n",
                            "      <td>NV</td>\n",
                            "      <td>6/6/2005</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>44.778429</td>\n",
                            "      <td>37.140811</td>\n",
                            "      <td>35.353846</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>10.4</td>\n",
                            "      <td>7.2</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.487447</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>4</td>\n",
                            "      <td>4</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>Miscellaneous</td>\n",
                            "      <td>30.700600</td>\n",
                            "      <td>-90.591400</td>\n",
                            "      <td>LA</td>\n",
                            "      <td>9/22/1999</td>\n",
                            "      <td>...</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>0.214633</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 43 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 67
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Observing the data sets, we see some irrelavant information in the front and serveral factors that correlated to the magnitude of the wilrawire. What we do next is to extract the valuable information. <br>\n",
                "\n",
                "In the U.S., California is the state \"known\" for wildfires. Since the magintude of wildfires is closely related to environmental and geographical factors, let's focus on cases in California. <br>\n",
                "\n",
                "Since our goal is to predict the magnitude of the wilrawire based on whether conditions, then we select columns named `fire_size`, `fire_size_class`, and columns of name with `Temp`, `Wind`, `Hum`, `Prec`. However, bearing the fact that wildfire tends to accumulate around places such as california "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "source": [
                "# select the columns\n",
                "raw = raw.loc[raw['state']=='CA']\n",
                "\n",
                "frames = [raw['fire_size'], raw['fire_size_class'], raw.loc[:, 'Temp_pre_30':'Prec_cont']]\n",
                "# purify the data set with only selected columns\n",
                "raw = pd.concat(frames, axis=1)\n",
                "raw"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "       fire_size fire_size_class  Temp_pre_30  Temp_pre_15  Temp_pre_7  \\\n",
                            "78         450.0               E    27.850483    28.165097   28.499405   \n",
                            "88           3.0               B    19.685119    19.242174   19.495294   \n",
                            "93           1.0               B    -1.000000    -1.000000   -1.000000   \n",
                            "123          3.0               B    33.901235    35.444444   35.107143   \n",
                            "159        200.0               D    23.892857    22.357143   21.400000   \n",
                            "...          ...             ...          ...          ...         ...   \n",
                            "55354     4000.0               F    -1.000000    -1.000000   -1.000000   \n",
                            "55363    70868.0               G    -1.000000    -1.000000   -1.000000   \n",
                            "55364     5702.0               G    28.425403    28.425403   28.166667   \n",
                            "55365     3261.0               F    -1.000000    -1.000000   -1.000000   \n",
                            "55366    76067.0               G    21.590225    21.312500   21.963095   \n",
                            "\n",
                            "       Temp_cont  Wind_pre_30  Wind_pre_15  Wind_pre_7  Wind_cont  Hum_pre_30  \\\n",
                            "78     33.900000     2.580000     2.664543    2.769643   2.237500   44.706207   \n",
                            "88     19.063744     3.893413     3.755263    3.401190   3.751422   67.688935   \n",
                            "93     -1.000000    -1.000000    -1.000000   -1.000000  -1.000000   -1.000000   \n",
                            "123    34.500000     4.684711     4.325000    4.509091   4.572222    0.000000   \n",
                            "159    22.444444     1.303571     1.092857    2.040000   1.140741    0.000000   \n",
                            "...          ...          ...          ...         ...        ...         ...   \n",
                            "55354  -1.000000    -1.000000    -1.000000   -1.000000  -1.000000   -1.000000   \n",
                            "55363  -1.000000    -1.000000    -1.000000   -1.000000  -1.000000   -1.000000   \n",
                            "55364  27.646067     2.649395     2.649395    2.667722   2.529158   43.755556   \n",
                            "55365  -1.000000    -1.000000    -1.000000   -1.000000  -1.000000   -1.000000   \n",
                            "55366  19.016883     1.795485     1.628065    1.036905   1.208073   50.521912   \n",
                            "\n",
                            "       Hum_pre_15  Hum_pre_7   Hum_cont  Prec_pre_30  Prec_pre_15  Prec_pre_7  \\\n",
                            "78      42.983379  49.000000  39.375000          0.0          0.0         0.0   \n",
                            "88      68.160550  64.461538  66.811705          0.0          0.0         0.0   \n",
                            "93      -1.000000  -1.000000  -1.000000         -1.0         -1.0        -1.0   \n",
                            "123      0.000000   0.000000   0.000000          0.0          0.0         0.0   \n",
                            "159      0.000000   0.000000   0.000000          0.0          0.0         0.0   \n",
                            "...           ...        ...        ...          ...          ...         ...   \n",
                            "55354   -1.000000  -1.000000  -1.000000         -1.0         -1.0        -1.0   \n",
                            "55363   -1.000000  -1.000000  -1.000000         -1.0         -1.0        -1.0   \n",
                            "55364   43.755556  44.443975  35.924406          0.0          0.0         0.0   \n",
                            "55365   -1.000000  -1.000000  -1.000000         -1.0         -1.0        -1.0   \n",
                            "55366   46.310627  37.178571  58.063802          0.3          0.3         0.0   \n",
                            "\n",
                            "       Prec_cont  \n",
                            "78           0.0  \n",
                            "88           0.0  \n",
                            "93          -1.0  \n",
                            "123          0.0  \n",
                            "159          0.0  \n",
                            "...          ...  \n",
                            "55354       -1.0  \n",
                            "55363       -1.0  \n",
                            "55364        0.0  \n",
                            "55365       -1.0  \n",
                            "55366       18.8  \n",
                            "\n",
                            "[3847 rows x 18 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>fire_size</th>\n",
                            "      <th>fire_size_class</th>\n",
                            "      <th>Temp_pre_30</th>\n",
                            "      <th>Temp_pre_15</th>\n",
                            "      <th>Temp_pre_7</th>\n",
                            "      <th>Temp_cont</th>\n",
                            "      <th>Wind_pre_30</th>\n",
                            "      <th>Wind_pre_15</th>\n",
                            "      <th>Wind_pre_7</th>\n",
                            "      <th>Wind_cont</th>\n",
                            "      <th>Hum_pre_30</th>\n",
                            "      <th>Hum_pre_15</th>\n",
                            "      <th>Hum_pre_7</th>\n",
                            "      <th>Hum_cont</th>\n",
                            "      <th>Prec_pre_30</th>\n",
                            "      <th>Prec_pre_15</th>\n",
                            "      <th>Prec_pre_7</th>\n",
                            "      <th>Prec_cont</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>78</th>\n",
                            "      <td>450.0</td>\n",
                            "      <td>E</td>\n",
                            "      <td>27.850483</td>\n",
                            "      <td>28.165097</td>\n",
                            "      <td>28.499405</td>\n",
                            "      <td>33.900000</td>\n",
                            "      <td>2.580000</td>\n",
                            "      <td>2.664543</td>\n",
                            "      <td>2.769643</td>\n",
                            "      <td>2.237500</td>\n",
                            "      <td>44.706207</td>\n",
                            "      <td>42.983379</td>\n",
                            "      <td>49.000000</td>\n",
                            "      <td>39.375000</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>88</th>\n",
                            "      <td>3.0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>19.685119</td>\n",
                            "      <td>19.242174</td>\n",
                            "      <td>19.495294</td>\n",
                            "      <td>19.063744</td>\n",
                            "      <td>3.893413</td>\n",
                            "      <td>3.755263</td>\n",
                            "      <td>3.401190</td>\n",
                            "      <td>3.751422</td>\n",
                            "      <td>67.688935</td>\n",
                            "      <td>68.160550</td>\n",
                            "      <td>64.461538</td>\n",
                            "      <td>66.811705</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>93</th>\n",
                            "      <td>1.0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>123</th>\n",
                            "      <td>3.0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>33.901235</td>\n",
                            "      <td>35.444444</td>\n",
                            "      <td>35.107143</td>\n",
                            "      <td>34.500000</td>\n",
                            "      <td>4.684711</td>\n",
                            "      <td>4.325000</td>\n",
                            "      <td>4.509091</td>\n",
                            "      <td>4.572222</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>159</th>\n",
                            "      <td>200.0</td>\n",
                            "      <td>D</td>\n",
                            "      <td>23.892857</td>\n",
                            "      <td>22.357143</td>\n",
                            "      <td>21.400000</td>\n",
                            "      <td>22.444444</td>\n",
                            "      <td>1.303571</td>\n",
                            "      <td>1.092857</td>\n",
                            "      <td>2.040000</td>\n",
                            "      <td>1.140741</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>55354</th>\n",
                            "      <td>4000.0</td>\n",
                            "      <td>F</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>55363</th>\n",
                            "      <td>70868.0</td>\n",
                            "      <td>G</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>55364</th>\n",
                            "      <td>5702.0</td>\n",
                            "      <td>G</td>\n",
                            "      <td>28.425403</td>\n",
                            "      <td>28.425403</td>\n",
                            "      <td>28.166667</td>\n",
                            "      <td>27.646067</td>\n",
                            "      <td>2.649395</td>\n",
                            "      <td>2.649395</td>\n",
                            "      <td>2.667722</td>\n",
                            "      <td>2.529158</td>\n",
                            "      <td>43.755556</td>\n",
                            "      <td>43.755556</td>\n",
                            "      <td>44.443975</td>\n",
                            "      <td>35.924406</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>55365</th>\n",
                            "      <td>3261.0</td>\n",
                            "      <td>F</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.000000</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "      <td>-1.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>55366</th>\n",
                            "      <td>76067.0</td>\n",
                            "      <td>G</td>\n",
                            "      <td>21.590225</td>\n",
                            "      <td>21.312500</td>\n",
                            "      <td>21.963095</td>\n",
                            "      <td>19.016883</td>\n",
                            "      <td>1.795485</td>\n",
                            "      <td>1.628065</td>\n",
                            "      <td>1.036905</td>\n",
                            "      <td>1.208073</td>\n",
                            "      <td>50.521912</td>\n",
                            "      <td>46.310627</td>\n",
                            "      <td>37.178571</td>\n",
                            "      <td>58.063802</td>\n",
                            "      <td>0.3</td>\n",
                            "      <td>0.3</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>18.8</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>3847 rows × 18 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 68
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Let's take a closer look at the data. In row 4, there are `-1`s. This means the corresponding information is missing. So, how much such information is missing? We use `seaborn` and `numpy` to visualize it."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "source": [
                "import seaborn as sns\n",
                "import numpy as np\n",
                "\n",
                "# replace all 0 or -1 by NaN\n",
                "raw = raw.replace(0, np.nan)\n",
                "raw = raw.replace(-1, np.nan)\n",
                "# plot the heat map\n",
                "cols = raw.columns[:18]\n",
                "colours = ['cadetblue', 'lightcoral']\n",
                "sns.heatmap(raw[cols].isnull(), cmap=sns.color_palette(colours), \n",
                "            cbar=False).set(title='Specify Missing Data')"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[Text(0.5, 1.0, 'Specify Missing Data')]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 69
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ],
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAFFCAYAAADsCZrCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABNU0lEQVR4nO2dZ5gtRdW27wcOOUdF0hEJCggooJhJYgSMCAY4iCJ8ZEEQBUHRV0QEMbwgqIABAQlKFBA8igKScxQ8IOElZyQ/34+qDX2GCd1718z07LPu69rX7K7uXl1d07tXVa1Qsk0QBEEQzDTeFQiCIAjaQSiEIAiCAAiFEARBEGRCIQRBEARAKIQgCIIgEwohCIIgAEIhBH2IpOskrZ2/S9KRkh6WdPEoXe9dkm7q4fylJD0haeaS9QqCpoRCCEYVSe+UdIGkRyU9JOkfktYczWvaXsn21Lz5TuC9wBK239JEjqR9JVnSjgPKd87l++brnW97hR7qe4ftuW2/0K2MoZB0lKRnJT2eP9dK+q6k+RrImCZp/dJ1C9pHKIRg1JA0L3Aa8GNgQWBx4JvAM2NYjaWBabaf7PL8m4EtBpRtnssnCgfYngdYBNgSWAv4h6S5xrdaQdsIhRCMJssD2P6d7Rds/9f22bavBpA0JY8YfpxHEDdKWq9zsqT5JP1C0j2S7pL07eq0iqQvSroh93yvl/TmXD5N0vqStgJ+DrwtT8n8TNJTkhaqyFhd0v2SZhniHi4B5pS0Uj5+JWCOXN6RsbakOyvbe+T6Pi7pps49SXqLpEslPSbpXkkH5fLJecQxKW9PlbRfbpvHJZ0taeGK/M0l3S7pQUl71+3B237a9iXARsBCJOWApNdJOi/Le0DSbyXNn/f9GlgKODW34e65/PeS/i//3/7WaZ9gYhMKIRhNbgZekHS0pA9IWmCQY94K3AYsDOwDnCRpwbzvaOB5YFngTcAGwBcAJH0S2JfUW5+X9JJ7sCrY9i+AbYAL85TMl4CpwCaVwz4LHGv7uWHu49f5OpBGC78a6kBJKwDbA2vmXvn7gGl59yHAIbbnBV4HHD/MNT9NemEvCswK7Jblrwj8L/AZYDFgPtLIqza2HwfOAd7VqTbwXeA1wBuAJUlti+3PAXcAG+Y2PCCfcyawXK7f5cBvm9QhaCehEIJRw/ZjpDl8A0cA90s6RdKrKofdB/zQ9nO2jwNuAj6Uj/kAsLPtJ23fBxwMbJrP+wJpKuQSJ/5l+/Ya1TqapATIo43NSC/84fgNsFkeRWyat4fiBWA2YEVJs9ieZvvWvO85YFlJC9t+wvZFw8g50vbNtv9LUhyr5fJPAKfa/rvtZ4FvkNq3KXeTpvHIbXeO7Wds3w8cBLxnuJNt/9L247afISmPVZvYJYJ2EgohGFVs32B7iu0lgJVJvdAfVg65y9NnWLw9H7M0MAtwj6RHJD0C/IzUI4XUi72V5vyR9LJehmRsftT2sN5Htu8A/gX8D3CL7f8Mc+y/gJ1JL8n7JB0r6TV591akabQbJV0i6cPDXPb/Kt+fAubO318DvHR9208xYGRUk8WBhwAkLZrreZekx0gKb+GhTpQ0s6T9Jd2aj5+Wdw15TjAxCIUQjBm2bwSOIimGDotLUmV7KVLv9T8k4/PCtufPn3ltd+aq/0Oadmlah6dJPe7PAJ9j5NFBh18BuzLMdFHlGsfYfidJqRn4Xi6/xfZmJKX2PeCELgy79wBLdDYkzUGyB9RG0tzA+sD5uei7uZ6r5Omsz5KmkV66pQEiPg1snGXMB0zuiG5Sj6B9hEIIRg1Jr5e0q6Ql8vaSpCma6lTJosCOkmbJdoE3AGfYvgc4G/iBpHklzZSNn52pjJ8Du2WjsCQtK2npmlX7FTCFZHcYbvqnynEkG8Zw8/5IWkHSupJmA54G/kuaRkLSZyUtYvtF4JF8SlNX0xOADSW9XdKsJK+tWi9iSbNJWh34A/AwcGTeNQ/wBPCIpMWBrww49V5gmcr2PCRl/SAwJ2nkFPQBoRCC0eRxktH4n5KeJCmCa0k97Q7/JBknHwC+A3zCdmcKZHOSQfV60gvsBJIhFdu/z8cfk6/zB/Kc+EjY/gfwInC57Wk1z/mv7T/nOf3hmA3YP9/P/5EU3tfyvvcD10l6gmRg3jSPWGpj+zpgB+BY0mjhcZIdZjhX3t0lPU6aIvoVcBnw9oor7jeBNwOPAqcDJw04/7vAXnnqbrcs43bgLtL/ZjhbSDCBUCyQE4wXkqYAX8jTK2N97fOAY2z/fKyvXZI8/fMIsJztf49zdYIJTowQghkOpUjpN5OmgSYckjaUNGe2PxwIXMPLht0g6JoxVQh5fvXKyucxpTQAq0m6KJddKqlRioEgqIuko4E/k9xZHx/v+nTJxiTD+92k6bZNHUP9oADjNmWUfcDvIs0xHwEcbPtMSR8Edre99rhULAiCYAZlPKeM1gNuzcFEJkWbQnJju3vcahUEQTCDMp4jhF+SvDx+IukNwFkk97mZSB4Qw0adTjny6BgiB0EQNOSoLbcY0k150lhWpEP2n94I2DMXbQvsYvtESZsAvyAFvQw8b2tga4C3bT6F5ddee2wqHARBqznkjmnjXYW+YFxGCJI2BrazvUHefhSY37Zz1OqjOWJySNo4QoiHMgiCtjPfPvsMOUIYLxvCZsDvKtt383IyrXWBW8a8RkEQBDM4Yz5lJGlOUlKxL1WKvwgcopQP/mnytNBEY6elJo93FYJghqTfR+cl3y1HDbNvzBVCzs640ICyvwOrj3VdgiAIJgJjpfDGxagcBEE9+r3nG7SLUAhB0GJiGrIeoTjL0LVRWdKSkv6itKbtdZJ2yuXHVVJTTJN0ZS6fLOm/lX2H5fI5JZ2utJ7udZL2L3JnQRAEQSN6GSE8D+xq+3JJ8wCXSTrH9qc6B0j6ASmlbodbba82iKwDbf8lxyecK+kDts/soW5B0BdEzzcYS7pWCHkBk3vy98cl3UBalu96gBxPsAnJjXQ4OU8Bf8nfn5V0OZUVoYJgRiamjCYuJZX5hPIykjQZeBNpsZMO7wLutV2NKXitpCuAx4C9bJ9f2Yek+YENSYuHDHadVkcqR28uCILRYMJ4GeUFOk4kpRN+rLJrYPDZPcBSth/sLOMnaaXOOTkG4XfAj2zfNti1bB8OHA7tjFTud0r1UvpdcZbszUVb1aPf22ms6EkhSJqFpAx+a/ukSvkk4GNUYgtsP0Ne5s/2ZZJuBZYHLs2HHA7cYvuHvdRpPInhfT2ineoTbRWMJb14GYmUhO4G2wcN2L0+cKPtOyvHL5LXQEDSMqSFPW7L298mpb3eudv6BEEQBL3RywjhHcDngGs6rqXA12yfAWzK9NNFAO8GviXpeeAFYBvbD0laAvg6cCNwedIz/GSir3UbBMHYESOp+hw1zL5evIz+Tlq/YLB9UwYpO5E0vTSw/M6h5MzItHFONObGx55+b/OwIbSLcVsgp1fCqBwEwYxCSYU3XPrrXo3K04DHSVNAz9teI5fvAGxPCl473fbuOejsZ8AawIvATran5qC2qvvpEsBvbO/cS92CIAj6hYkUh7CO7Qc6G5LWATYGVrH9jKRF864vAth+Yy47U9Kath8HVqucfxnwksdSEATBSMSUURlGI7ndtsD+2c0U2/fl8hWBcztlkh4hjRYu7pwoaTlgUaYfMQRBEMzQTJQRgoGzJRn4WQ4cWx54l6TvkBa72c32JcBVwMaSjgWWJMUoLElFIZCC2Y7zEIaNtkcq9zulemH97hESvdWgNBMlUvkdtu/OU0DnSLoxy1wAWAtYEzg+xx38EngDKRDtduACko2hyqYkV9ZBiUjl8aXfX+Sl6HfPoKB/6Ukh2L47/71P0snAW4A7gZNyL/9iSS8CC9u+H9ilc66kC6isnSxpVWCS7ct6qVMwPW1NsNU22tpObWzzNo4UQ3GWoWuFIGkuYKac6XQuYAPgW8ATpAynUyUtD8wKPJDXUpbtJyW9l+SVdH1F5MDcR0EB2vhCaSPRTvWJthp7JoIN4VXAyTmyeBJwjO0/ZffSX0q6FngW2MK287TSWXnEcBevnBraBPhgD/UJRpnoGY49EbgVwASwIeSMpKsOUv4s8NlByqcBKwwjb5lu6xJMLA65Y1r0MseYtrZ3KKp2EWsqB7Vp40uljXUK6hMjoHbRa6TyLsAXSO6n1wBbkha42ZfkUfQW25dWjl+FFK08LylaeU3bT0uaCiwG/DcfukElfmGGpJ8f8JgyCoJ20otReXFgR2BF2/+VdDzJbfSfpLUQfjbg+EnAb4DP2b5K0kLAc5VDPlNVHhOReDnVI9opCNpJr1NGk4A5JD0HzAncbfsGgGxsrrIBcLXtqwBsP9jjtVtHvw9/2zg908a2inaqR4wU20cvRuW7JB0I3EGa6jnb9tnDnLI8YElnAYsAx9o+oLL/SEkvkFJkf3uoaOUZgTa+UKCdXkZtbKs2xjT0ezsFZehlxbQFSEnsXgu8BphL0iu8iypMAt4JfCb//aik9fK+z9h+I/Cu/Bk0WlnS1pIulXTpzVOndlv1IAhaQBuV1IxOL1NG6wP/zhHISDoJeDvJTjAYdwJ/7WRGlXQG8GbgXNt3AeQgt2NIEc+/GiggUleML/EDrke0U33a2FYz8silF4VwB7BWjkD+L7AeKU/RUJwF7J6PfxZ4D3BwNjbPb/sBSbMAHwb+3EO9xo0Z+UEKgmDi04sN4Z+STgAuJyWpuwI4XNJHgR+T7ASnS7rS9vtsPyzpIOASkpvqGbZPz2kvzsrKYGaSMjiit9saH9rY2wkmNtHJCMaSWEIzCIIJTyjO+ozaEppBEATB6DMRktsFA4heShAEo8FYvVtGdDuV9EtJ9+XspZ2yBSWdI+mW/HeBXD5Z0n8lXZk/h+XyeSplV0p6QNIP874vS7pe0tWSzpW09CjdaxAEQTAMdUYIRwE/YXo30K+S3EX3l/TVvL1H3ner7dWqAmw/DrxUJuky4KS8eQWwhu2nJG0LHAB8qvGdtIAwKgfB+BCj8zKMOEKw/TfgoQHFGwNH5+9HAx+pe0FJywGLAudn+X+x/VTefRGwRF1ZQRAEQTm6tSG8yvY9ALbvyYvfdHitpCuAx4C9bJ8/4NzNgOOGSE2xFXDmUBeVtDWwNcDbNp/C8muv3WX1g25oY0qGNhLtVJ82pkNpI2M1AqrldippMnCa7ZXz9iO256/sf9j2ApJmA+a2/aCk1YE/ACvZfqxy7PWkjKeXDbjGZ4HtgffYfmakOvWz22m/D38jqVkQjB+j4XZ6r6TF8uhgMeA+gPwifyZ/v0zSraSkdpcCSFoVmDSIMlgf+Do1lUG/0++9nZJEWwVtpa0jxaOG2detQjgF2ALYP//9I4CkRYCHbL8gaRlgOeC2ynmbAb+rCpL0JtLaCe+f0RfFCYKgf5iII+ERFYKk3wFrAwtLuhPYh6QIjpe0FSmn0Sfz4e8GviXpeeAFYBvbVYP0JsAHB1zi+8DcwO/zGgp32N6o6zsKgiDoM1ozQrC92RC71htYYPtE0noGQ8laZpCy9Ueqw0Qh5rODIJjIRKRyQWI+OwjGh+iMlaHbSOX9cmTxlZLOlvSaXP5eSZdJuib/XbdyzqySDpd0s6QbJX18wHU+IcmS1ih5g0EQBEE9uo1U/r7tvQEk7Qh8A9gGeADY0PbdklYmrYGweD7n68B9tpeXNBOwYEeYpHmAHYF/9nY740v0UoIgmMjUsSH8LcchVMseq2zORVrfANtXVMqvA2aXNFt2Jf088Pp83Isk5dFhP1LKit26uIfWEFNGQRB0mIgdxK5tCJK+A2wOPAqsM8ghHweusP2MpPlz2X6S1gZuBba3fW92O13S9mmSJrRCmIgPQBAEQYdeVkz7OvB1SXuSIoz36eyTtBLwPWCDynWWAP5h+8uSvgwcKGkL4GBgSp1rtj11RYwQgiBoO0cNs6+r1BUD9i0NnF5Ja7EEcB6wpe1/5DIBTwDz2H5R0pLAn4C3k0YLT2RxryYl0tvI9nDrM/d16oogCJrR76PzonEIW25RNnWFpOVs35I3NwJuzOXzA6cDe3aUAYBtSzqVFOB2HimG4XrbjwILV+ROBXYbSRkE40NbQ/HbRrRTffr9RV6Ktkcqf1DSCsCLwO0kDyNIU0fLAntL2juXbZBTUuwB/DovjHM/sGXB+wjGgH5/OZUi2qk+pdoqFEsZuo1U/sUQx34b+PYQ+24npbYY7lprj1SfIAiCYHSISOWCRC8lCIKJTCiEgvT7VEEsZlKPsCHUo9/baSJ2EOvYEH4JfJgUZbxypXwHks3geZKX0e6SFgJOANYEjrK9fT52HvKSmZklgN/Y3lnSUqRlOOcHZga+avuMEjc31kzEB2A8iHaqT7RVPaKdytBV6gpJ65DWVV4lB551ltB8GtgbWDl/ALD9OLBa5fzLgJPy5l7A8bYPlbQicAYwubvbCYIgCLqlq9QVwLbA/p3VzToL29h+Evi7pGWHkidpOWBRXh4xGJg3f58PuLvJDbSJfveYiGF5PaKd6jERF5Dpd7q1ISwPvCunr3iaFDtwSc1zNwOO88sRcfsCZ+cpqLmAIddHaHukcr8/lP1+f6WIdqpHtFP7GDH99RBMAhYA1gK+Qlo9bcjotwFsyvTLaG5GsjcsQVpN7dc5G+orsH247TVsr9E2ZRAEQTDR6VYh3Amc5MTFpAC1hUc4B0mrApNsX1Yp3go4HsD2hcDsdWQFQRAEZelWIfwBWBdA0vLArEyfznooNmP60QGkNZnXy7LeQFII93dZryAIgqBLuk1d8Uvgl3kVtWeBLTo2AUnTSEbiWSV9hJS64vosbhPStFCVXYEjJO1CMjBPqdgXJhRtNCaWJOIQ6tHv/vUlCTtCu6iV7bSNtDHbaTzcQRC0nfn22adsttNgcKI3V49op/r0c1tFB6p9dBWpnI3DhwFzA9OAz9h+TNJ7gf1JNoVnga/YPi+f8ydgsXzN84HtbL8gaQrwfeCufMmf2P55sTscQ+IBr0e0U32irYKxpKtIZeDnpNiDv0r6PMn1dG+SYXlD23dLWhk4C1g8n7NJVhoipbf4JHBs3ndcJ83FRKafe3MQI4S6xEs8mKh0G6m8AvC3/P0c0ot/b9tXVI65Dphd0my2n7H9WOWas5IMyMEEot9f5KWIdhp7QgmXoVsbwrWkldL+SOrpLznIMR8HruiktwCQdBbwFuBM0ijhpWMlvRu4GdjF9n8Gu2hEKgdBEIweXa2pLOn1wI+AhYBTgB1tL1Q5fqVcvoHtWwfImh34LXCY7XNyhtQncpK8bUhTS+uOVKc2ehkFQTA+RGesPsW9jGzfCGwALwWmfaizT9ISwMnA5gOVQT73aUmnkLKlnmP7wcruI4DvdVOnIAhmXPo9UV7J+ztqmH1dKQRJi9q+L+cc2ovkcYSk+YHTgT1t/6Ny/NzAPLbvkTSJFJx2ft63mO178qEbATd0U6dgcMIFsh7RTvVpo3NBG1/iJRmr++s2UnluSdvlQ04CjszftweWBfaWtHcu2wAQcIqk2UiL4JxHViLAjpI2Ii208xAwpcd7Ciq08UfXxhdmG9up34l2ah8RqVyQeMCDIGg7Eak8RvT7AjmliN54feKZCsaSOlNGS5KC0l5NSnN9uO1DJH0f2JAUkXwrsKXtR/I5e5LSWr9A8kA6K5dvBnyNFINwN/BZ2w9IOhhYJ19yTmBR2/OXusmxIn509Yh2qk+0VTCWjDhlJGkxYDHbl0uaB7gM+AiwBHCe7eclfQ/A9h55XeTfkeINXgP8mbTCmkhKYMWsBA4AnrK974Dr7QC8yfbnh6tXG6eMgiAYH0Jx1qenKaPsAXRP/v64pBuAxW2fXTnsIuAT+fvGwLE5IO3fkv5FUg6XkpTCXJIeJKXI/tcgl9yMZLgOWkY/G5VLEh5L9Yh2qk9rvIyq5AC1NwH/HLDr88Bx+fviJAXR4U6SArlQ0rbANcCTwC3AdlUhkpYGXkvyQppwRC+lHtFO9Ym2qke0Uxlqr5iWYwlOBHau5CVC0tdJLqO/7RQNcrolzQJsS1IorwGuBvYccNymwAm2XxiiDltLulTSpTdPnVq36kEQBEENao0Q8sv8ROC3tk+qlG9BSo29XmWVszuZPrfREiTbwWoAnehlSccDXx1wqU0ZMGqoYvtw4HBopw2h34etQdBWYoRQhhFHCDld9S+AG2wfVCl/P7AHsJHtpyqnnAJsKmk2Sa8FlgMuJq13sKKkRfJx76USlSxpBWAB4MLebikIgiDohjojhHcAnwOukXRlLvsaKbndbMA5SWdwke1tbF+Xe//Xk6aStstTQHdL+ibwN0nPAbczfVTyZiRjdOt6/kEijMr1CGNpfeKZqkdrjMq2/87gdoEzhjnnO8B3Bik/jJdTVgzct+9IdQmCoH9o6zRPW+s1FkSkclCbfu+FlSLaqR4Rsd4+QiEUJB7KIAgmMr2krtgX+CJwfz70a7bPyOcMlbriU8DXSRlPT7e9ey5/N/BDYBVgU9vV1dQmDP3eM4y58XpEO9UnOlHtos4I4Xlg12rqCknn5H0H2z6wenBOXbEpsBI5dUVeRGd+4PvA6rbvl3S0pPVsnwvcQTIw71bipoLRod9fTqWIdqpPP7fVRFR2XaeuGOaUoVJXPA/cbLszovgzad3lc21PA5D0Yrc3Eow+4RFSjxgh1GcivjT7mV5SV7wD2F7S5qQ8RbvafpghUlcA5wKvzzLuJCXIm7Xh9bcGtgZ42+ZTWH7ttZucHvRIv7+cShHtVJ9I790uaiuEgakrJB0K7EdKZb0f8ANSTqNBU1fYfjjnMjqOZIu4AFimSWXbHqkcBMH4EEq4PkcNs6/r1BW2763sPwI4LW8OlboC26cCp+ZztiYZnfuG6KUEQTCR6SV1xWKVwz4KXJu/D5W6AkmL5r8LAP8P+HmJmwiCIAh6p5fUFZtJWo00ZTQN+BLAMKkrAA6RtGr+/i3bNwNIWhM4mZTLaENJ37S9Uo/3Nub0+7A1jMr1CKNyPWJE3T7GOnXFZkMcfwlpaikIgiAYJyJSOahNeISMPdFWwVjSS6TyaqREdbOTpob+n+2OrWCoSOXvAJsDC9ieu3KNbUjrILwAPAFsbfv6UjcZtIt+ngYJxodQnGXoJVL5AOCbts+U9MG8vfZQkcrZjnAq8BPS8plVjsmZUJG0EXAQ8P4C9zemxEMZBMFEppdIZQPz5sPmI7uWMnSk8oW2LwLI6ydUr/FYZXOuLHvCET3fIBgfojNWhl4ilXcGzpJ0IMl99e35sKEilUeSvR3wZVL08rpN6hUEwYxNv6fSLnl/Rw2zr5dI5W8Du9g+UdImpFiF9RkiUnkk+bZ/CvxU0qeBvYAtBqlDq1NXtPFBCoJg4jNW7xbVWbEyRyqfBpzVCU6T9Cgwv23n4LVHbc+bDcrY/m4+7ixgX9sXVuQ9UTUqD7jWTMDDtucbrk6RuiIIgg7RGavPfPvsM1inHajnZTRopDLJZvAeYCppiqdjKD4FOEbSQSSj8kuRysNcYznbnfM/xCuNzkEQBEPS71NGY0UvkcpfJEUeTwKeJk/lDBepLOkA4NPAnJLuBH6e11LeXtL6wHPAwwwyXRQEQTAUM/JLvCS1pozaSEwZjT2RuqIekbqiHvESHx96mjIK6hMPeD2ineoTbRWMJaEQCtLPvbkgaDP9rjhb43YqaXbgb8Bs+fgTbO8jaUHSYjeTSdlON8mL4MwK/AxYg5TqYifbU7Os1XN95iAlx9vJlTkrSZ8Afg+safvSJjfZBvr9oQyCYHwYq3dLnRHCM8C6tp/I7qd/l3Qm8DHSesj7S/oq8FVgD5KxGdtvzOsfnClpTdsvAoeSjM8XkRTC+4EzAXJajB1JQW8TkhghBMH4EJ2xMtRJXWFSwjmAWfLHpBQVa+fyo0nup3sAK5LWT8b2fZIeAdaQ9B9g3k48gqRfkdZVPjPL2I+UD2m33m5p/IiHMgiCiUzdJTRnBi4DlgV+avufkl6V8xxh+57OamjAVcDGko4lLaW5ev77IimNRYeXUlpIehOwpO3TJA2pENoeqdzGEUIblVS0U32irYKxpJZCyHEEq0maHzhZ0srDHP5L4A3ApcDtwAWkeIRBU1rkyOSDgSk16nE4cDiE22ld2vhCaSPRTvWJtprYHDXMvkZeRrYfkTSVNPd/r6TF8uhgMeC+fMzzwC6dcyRdQIo8fpjpV0VbghTtPA+wMjA1Z0F9NXCKpI0momG53ynRO5wRXigRs1GPfm6nQ+6Y1roI6pHqM2JgmqRFgOeyMpgDOBv4HiltxYMVo/KCtneXNGeW+6Sk9wJ72353lnUJsAPJcHwG8GPbZwy43lRgt5GUQRtHCDGUDoKg7fQamLYYcHS2I8wEHJ/n+i8Ejpe0FXAH8Ml8/KKktNgvAneR0l502JaX3U7P5GWDcl/Qxl5KSfq5N1eSiFSuT3Si2kWkrgiCIJiBOGrLLSJ1xVgQvZ0gCCYyvUQq70eKRXiRZFCeYvvuvKraDcBNWcRFtrfJsmYlram8dj7v63mBnaVIsQzzAzMDXx1oW5gI9PvwPgjaSnTGytBLpPL3be8NIGlH4BvANvmcW22vNoisrwP32V4+u5sumMv3ItkmDpW0IsngPLnbmxov4qEMgmAi03Wksu3HKofNRY1lMoHPA6/Pcl8EHuhcBpg3f5+P5I464YgRQhCMD9EZK0PXkcq5/DvA5sCjwDqVU14r6QrgMWAv2+fnoDaA/SStDdwKbG/7XmBf4GxJO5CUy/pD1KPVkcr9TngZ1SO8jOrR1naakZVLIy+jTqQysIPtayvlewKzZ9vCbMDcth/M2U3/AKwEzArcD3wi2w2+DLzJ9ufyd9n+gaS3kZbsXDmPIgaljV5GM/KDFATBxKDYAjkDIpWvrew6Bjgd2Mf2MyS7A7Yvk3QrsDxphPEUSaFASnO9Vf6+VZaJ7QuzIXthcvTzRKGfe3NB0Gb6vTPWpvUQBkYqrw98T9Jytm/Jh20E3Fg5/iHbL0haBlgOuM22JZ1K8jA6D1iPtO4ypMC29YCjJL0BmJ00mgiCIBiRfu+MtWk9hKEilU+UtALJffR2XvYwejfwLUnPAy8A29h+KO/bA/i1pB+SXvhb5vJdgSMk7UIyME9xk7msIAhmaPp9hDBW1PEyuhp40yDlHx/i+BOBE4fYdztJYQwsvx54x0h1CcafSG5Xj342wJdK2lb6JV6qrUreX8k6jQWRuiIIgqBCv482ejIqDxWpnPftAGxPWu/gdNu75/JVSOsqz0uaUlrT9tP9vqZyv9PPvd6StNWdso30+8t3otFLpPIcpNQVq9h+prNimqRJwG+Az9m+StJCwHNZVl+vqdzv9PvLqRTRTvWZaFMq/U4vaypvC+yf3Uyx3XER3QC42vZVufxBgLyITl+vqRwEQTAatMbtFIZcU3l54F05Wvlp0qI2l5BiDizpLGAR4FjbB5DWT+5pTeW2E72UIAhGg7F6t8xU5yDbL+RkdUsAb8lrKk8CFgDWAr5CWixHufydwGfy349KWo+R11TedaR6SNpa0qWSLr156tQ6VQ+CIAhq0kuk8p3ASXlK6eK8QtrCufyvth8AkHQG8GaSXaGnNZVtHw4cDu30Mur3ueMwKtcjjMr1iBF1++g6UplkV1iX9CJfnpSr6AHgLKCztvKzpLWXD7Z9j6THJa1FMhxvTlpT+VGSIulcbyo11lRuI/GA1yPaqT7RVsFY0kuk8qzALyVdS3rxb5FHCw9LOgi4hGR8PsP26VlWrKk8gYkRQj1ihFCfUHjtIgLTgiCY8IRiqc9wgWm1jMpBEARB/xMKIQiCIAB6SF0haVXgMGBuYBrwmc6ymnnBnK1I2U53tH1WLh80dYWkbYDt8vFPAFvnhHcTihi2BkEwkekldcWPSd5Af5X0eVIswt6SVgQ2Ja2S9hrgz5KWt/0CQ6euOMb2YQCSNgIOyvsmFP1uAAyCttLvnbHWRCoPk7piBdLIAeAckrvp3qT8RsfmlBb/lvQvUjDbNIZIXdEZWWTmyvInHP3+UAZBMD60aYGcoVJXXEtaKe2PwCeBJfPhi5NGAB06KSqeY4jUFfka2wFfJsUzrDtEPbYmjTB42+ZTWH7ttetUf8zo9xFCuFPWI9qpPtGJahe1FEKe7llN0vzAyTl1xeeBH0n6BnAKKRYBhkhRMUx55xo/BX4q6dPAXsAWg9Sj1ZHK/U6/v5xKEe1Un2irerRqhNChmrrC9oGkzKbkSOUP5cPu5OXRArycouJOBk9dMZBjSbaGGZZ+7zWVfAlEW9Wj39spKEPXqSskLWr7vpycbi+SxxGk0cIxOVr5NcBywMW2XxgsdUW+xnK2b8nnfwi4hRmYtvaa2vhSaWNbRTvVp41tNSPTS+qKnfK8P8BJwJEAtq+TdDxwPWklte3ylBMMnbpie0nrk+wMDzPIdFEQBP1F2FrqE2sqj0DYEIIgaDNtVXhHbblF92sqB0EQtJ2YeipD7dQVkmaWdIWk0/L29yXdKOlqSSdnDyQkLSTpL5KekPSTATJWl3SNpH9J+lFeUKe6/xOSLGmNAvcWBEEQNKDJCGEn4AZg3rx9DrCn7eclfQ/YE9iDtJzm3qRFb1YeIGOoSGUkzQPsSDI4By0k0l/Xo61TBW0jevX1aZXbqaQlSN4/3yEFj2H77MohFwGfyOVPktJbLDtAxmIMEamcD9kPOACYsGsq9zv9/HIqSbRTPaKdxoejhtlXd4TwQ2B30nKXg/F54LgRZCzOEJHKkt4ELJm9l0IhtJgSPZUZ4UUQo6l6xCihHjstNXlMfnt14hA+DNxn+zJJaw+y/+sk99LfjiRqkDLnOIaDgSk16tLq1BXxcNcj2qk+0VYBlHsORpJTx6j8DmCjnJzuWGBdSb8BkLQF8GFS6uuR3ECHilSeh2RrmJqvsRZwymCGZduH217D9hptUwZBEAQTnTrZTvckGYzJI4TdbH9W0vtJRuT32H6qhpx7BotUtv0osHDnuJwaYzfblza/nfGl34f3QRCMD60yKg/BT0iL5pyTvUcvsr0NQCfVNTCrpI8AG+QFb4aKVA6CIOiamForQ9PkdlOBqfn7ssMcN3mI8kt5pSvqwGPWblKnNhEPZRAEE5mIVC5ITBkFQdChrfEoRw2zLxRCUJtwpaxHW18EbSNG1PVpnQ0hZzu9FLjL9ocl7Qt8Ebg/H/I122dIWgg4AVgTOMr29hUZ3yEZkxewPXelfBtgO+AF0nKdW2ebQ9Ai+vnlVJJop3rEuhjto5fUFQAH54VyqgyXuuJUkjF64HoHx9g+DEDSRsBBpLQWQRAEMzytmjIaLHXFUAyVuiLvuyjLG1j+WGVzLipLawbtIaaM6hFTRvWIXn19xqqt6mY7/SEpdcWLA8q3z9lOfylpgV4qImk7SbeS8hntOMQxW0u6VNKlN0+d2svlgiAIggGMqBCqqSsG7DoUeB2wGnAP8INeKmL7p7ZfRwp222uIYyJSOQj6hH4e/UxU6kwZdVJXfBCYHZhX0m9sf7ZzgKQjgNMK1elYkrIJWkj8iOsR7TQyh9wxrVg7tVFWW+s0HI2W0KykrviwpMVs35PLdwHeanvTyrFTgDWqXkaVfU8M8DJazvYt+fuGwD62h10kp41LaMacaBAEbWe+ffYZlSU0D5C0GskAPA34UmfHUKkrJB0AfBqYU9KdwM9t70uyRawPPAc8DGzRQ72CIAiCLugldcXnhjlu8hDlu5OM0wPLd2pSjyAIgqA8EalckH6fNw6303qE22k9Yoq1ffQSqXwcsELePT/wiO3VJM0C/Bx4c5b/K9vfHSDrFGAZ2yvn7YOBdfLuOYFFbc/f9V2NE/GA1yPaqT7RVsFY0nWksu1PdXZI+gHwaN78JDCb7TdKmhO4XtLvbE/Lx36MlJ7iJWzvUpG1A/Cm5rcy/vRzby4I2kwozjL0HKmsFHa8CbBuLjIwl6RJpHUPngUey8fOnc/fGjh+iMttBuzT6C6CMSGmjOoRU0b1iJd4+6g7QvghyRg8zyD73gXc23EbJSW225gUrDYnsIvth/K+/UgBbIOusCZpaeC1wHlD7G/1msr9Tj+/nEoSSdvqEe3UPkZUCNVI5RyHMJDNgN9Vtt9Cylr6GmAB4HxJfyZNNS1rexdJk4e43KbACbZfGGyn7cOBwyHiEIJgohO/l/bRU6Rynhb6GLB65fhPA3+y/Rxwn6R/AGsACwGr5xiFScCikqYOWCFtU1Ia7CAIgmCMGVEh2N4T2BOmi1TupK1YH7jR9p2VU+4A1pX0G9KU0VrAD21fTU5JkUcIp1WVgaQVSCOKC3u6o3EkplSCYOLTxpFLq9JfD8OmTD9dBPBT4EjgWkDAkVkZjMRmwLFukkujZbTxQQqCYOLTtvTXQIpUtv3hyvaUzsI2lbInbH/S9kq2V7T9/UHkTOvEIFTK9rX91aY30CZKafGSvYE2jlraeH9tbCdo5/21ta2C3mmU3K5NtNGoHATBxKffR/o9J7fLhuDHSd5Dz9teQ9KCwHHAZFJyu01sPzzCmsp/AhbL1z0f2M72CxGpHARBMP40sSGsY/uByvZXgXNt7y/pq3l7D4ZfU3kT24/lYLYTSFHNx0ak8sQgAq7qEe1Unwh2rMdYdTZ7MSpvDKydvx9NyoK6xwhrKnfWTp4EzMrgaydHpHJL6fcfXSminepTcgGZoHfqKgQDZ0sy8LMcIPaqzgI5tu+RtGgdQZLOIgWvnUkaJVT3DRupHAQzGvGiC8aSugrhHbbvzi/9cyTd2O0Fbb9P0uzAb0n5j86p7B42UjlSVwQzGjHaqEcozjLUUgi2785/75N0MqmHf29nGU1JiwH31b2o7adzCuyNeaVCGDJSue2pK9pIG38obXzJtbGdgmCsqZPLaC5gJtuP5+8bAN8CTiEtdbl//vvHEeTMDcyTFcgk4IMkT6PO/gkfqRwvlXpEOwVBO6kzQngVcHJyDGIScIztP0m6BDhe0lakdBWf7Jww2JrKwIPAKZJmA2Ym2QmqQW0TPlK5jT3fIAgmPq3xMrJ9G7DqIOUPAusNcc7kIcStOcx19h2pLkEQBIMRo84yxJrKBYmHMgiCiUwohILElFEQjA/RGStDreR2kqZJukbSlZIuzWWflHSdpBclrVE5dlZJR+bjrxpsUR1Jp0i6trL9ZUnXS7pa0rk5HmHCUeqhLPlwt1FW1GnsZfV7nYIy1Epul43Ea1RTV0h6A/Ai8DPSGgkdRbFdPnbLHLdwJrCm7Rfz/o8BnwBW6WQ8lbQO8E/bT0naFljb9qeGq1Mb3U7jAQ+CoO0Ml9yuUfrrKrZvsH3TILtWBM7Nx9wHPEJaMa3jevpl4NsDZP3Fdmed5YuAJbqtVxAEQdAdvaSuGIqrgI0lHQssSVpec0ngYmA/4AfAU0OfzlakUcUraHukcr/bECJpWz2ineoTo+p20XXqCtt/G+LYXwJvAC4FbgcuAJ6XtBqwrO1d8hKar0DSZ0mjifcMtj8ilceXfn85laKN7dTGF+9OS02O5HYto5fUFYMqBNvPA9V01hcAt5Be8qtne8QkYFFJUzvrKktaH/g68B7bz3R7Q+NJPJRBUJ/4vbSPXlJXDHX8nCRj9ZOS3ktaUOd64Hrg0HzMZOC0ijJ4E8k4/f5sd5iQtLFnGAQzAqFcytBL6oqPAj8GFgFOl3Sl7fcBiwJnSXoRuAv4XI1rfB+YG/h9vs4dtjdqfDdBEMyQlOyMtVG5lLy/o4bZF2sqB0Ew4WnjS7yt9LymchAEQZvp9+na1iS3g5cC0x4HXiDZBNaQtB9pPYMXSWshTOkYn/M5S5HsBvvaPnCAvFOAZSqBaduQ1kF4AXgC2DrbHYIgCEYkRghlaDJCWKcaqQx83/beAJJ2BL4BbFPZfzCDxBPkSOUnBhQfY/uwvH8j4CDg/Q3q1le09eEOF8F6tLG32sY2b2M7zej0Eqn8WGVzLlLwGgB5DYTbgOuq5wwTqTykrBmR+KEEMwJtVFIzOj1FKkv6DrA58CiwTi6bC9gDeC+w2wA5Q0Yq5xxIXwZmJa21PEPTz0qhn++trfR7m++01ORiCqakrFK0ystI0muqkcrADtVIZUl7ArPb3kfSgcDFto+XtC/whO0Dc6TyfrY3rMQhrDzItT4NvM/2FoPsq6auWL1tqSuCerTtx1aafn/5tpF+f6ZKMpyXUWO30+pLvlK2NHC67ZUlnU/KXQQwP8no/A2SwXhv4FlypDJwQSc4rSJrJuBh2/MNV482up3GQxkEQdvpye10qEhlScvZviUfthFwI4Dtd1XO3ZekPH6Si4aKVK7K+hAp1cWEI3qGQTA+RGesDL1EKp8oaQXSCOB2pvcwasr2OZfRc8DDwCumi4IgCILRZUSFYPs2YNVByj9e49x9hyifBqxc2d5pJFlBEATB6BKRykFtSnpx9DOxHkJ9+vmZmojTWKEQgtq08UfXRqKd6hPBju0iFEIQBBOeNirhto4UjxpmX9eRykEQBEGfYbtvP6QkeX0rK+oU99fWOvX7/bWxTiVk9fsIYes+lxV1GntZUaexlxV1GiNZ/a4QgiAIgpqEQgiCIAiA/lcIh/e5rKjT2MuKOo29rKjTGMmasGsqB0EQBGXp9xFCEARBUJNQCEEQBAEQCiEIgiDIhEIYZSTNJ+lTkr4saZf8ff4Ccl8r6WOSXl+gmr3W5dd1yoKgCZJmq1MWlKMvFYKkpfP6CkiaQ9I8XcqZK6/ghqTlJW0kaZYG528OXA6sDcwJzEVae/qyvK9JXf5Q+b4xcB6wIfBHSVMayHlI0s8lrae8yEUBVhpwjZmB1ZsKGQ3l2SbFCeWUp6T3STpU0imS/pi/v7+hjIUHbH9W0o8kbd302ZC0SpPja3JhzbIhkfR6SXvk+zokf39DrxWT9M78nG7Q8Lz5e732IDLPrVNWi1Ih0235AF8ELgFuzdvLAed2Kesy0ot8ceA/wMnAbxucfxMw/yDlCwA3N6zLFZXvFwCvzd8XBq5qWKftgX8AdwGHAGt12T57Ao8DzwOP5c/jwIPAdxvK2hy4lbSq3l75c1gu27yBnD9Uvm8M/Bs4Mt/3lIZ1egj4ObAe2SOvwPN5+YDtmYHrG8r4IXAGsCnwzvzZNJcd0k1dcnufRVqc6vfAwQ3r9ALwL2A/YMUe2+jVpA7FDcCbgDfnz9rAjQ3k7AFcCXwV+Gz+fLVT1rBOF1e+fzHL2Cf/jmrLyr+VPwNbDfZuaFin2YEFgavyO2XB/JkM3NCVzF4q1MZP/kfNOuAFek2Xsi7Pf3cAds/fr2hw/s3AfIOUzwfc0k1d8veLB+xrUqeqnKWA3UmjmNuA/+mynRq9/IeQUUR5UkhxVurURuU5aHsAavJcDWiry4G58vdZmv5mgCtIi159h6QYrsov38ldtNUWwF9y+/yl8jkF+FiTdgJmGaR81i5+f9W2ugRYJH+fq0lbAdcAHwZ+m//3fyQp8zm6aKedSB2eZ/Lv99/5cxWwfVfPaTcntfkD/LP6DySl+L66S1lXAG8DLgJW6vxDG5y/BS/3er+WP51e75SGdXmh8hJ5Fnh1Lp+1yf0xhPIAVgD26aHdFwfeDry782l4fhHlSSHFOYisNinPq4G3DFL+lobP542kHvjqDFCWwJXdtlWlLgeRRtYXdHmfH++xnW4Elh6kfGngpoayOr3whYBLu32uBjxTcwCbACdl5XBMl/e5Q6/PVOfTj+sh/FXS14A5JL0X+H/AqV3K2pnUszvZ9nWSliH1VGph+2hJpwDvI70wBUwF9rT9cJOK2J55iF1zAl9qIGrQ+tu+Cfhmkzp1kLQ/qZdzPUlxARj4WwMx3wEul3Q26SUC6SX8XtI0RF1WlfQYqa1nk/Rq2/8naVbS9EwTXppHt30HcABwQF5LfNOGsjpy9pS0OOmlNKlS3qStpgCHZtvYnblsSVKHYUoDOfeQXtoAD0lazPY9khYijWSaMJ3NwfbFwMWSdiV1ELrhNEmfJk2BVNvqWzXP3xk4V9ItTP9MLUsa+TVhPtIUsgBXnqu5GXDvI1B9pv4LHA8cL2k+4CMN69SR82NJb+eV7fSrprL6LlI5G4G3AjYgNf5Zto8oJHdu24/1KmsiIGlP29+teexNwCq2n+nxmgswvfK8k/T/a6Q8h5A9P/AG27WNkpIOsv3lXq89QOagytP2Rl3IejWVtrL9f4XqODMwm+2nGpzzadvHlLh+ReafgEdJL+JOW2H7Bw1kzEQarVSfqUtsvzDsifXlzwm8yva/ax6/m+0DS1y7IvPXwOtI0+XVZ2rHxsJKDTXa8gE+B8wzoOzDXco6BpiXNE94I6lH9ZUG578eOBM4Pf/DjgIeAS4mvZxK3XNXNpIRZF7e4NgzScpy3P//4/EhjfjqHnsT6WXb6zVnAmbK32clGV0XLHhPrx+ltjqxwbHXjsL1i7VRRWbxZx/4cYNjb6CQ00M/up3+GDh/gGtZ3SHmQFZ0GhF8hOTBsRRJ4dTlcOB/gd+Q3ET/RJqH3A/4SZOKZNfJwT4fJ3lllKbJMPgp4EpJP8vufT+S9KNGF0vugWdKOl3S6yQdJekRSReXcBPM17imhJxB+GSDY28jGW27RtJHSJ2Tu7IL8vnAgcDVkjbsRXaFswvJGcgyDY69QNIbu72QpHdIukHSdZLeKukc4FJJ/5H0tm7lDsL1BWV1eEeDY6+l0DugH20I/yZNGZ0gaV/bv6fZy63KLDnu4CPAT2w/J6nJHNs8tk8FkLSf7WNz+amSms7XH0fyTBjs+rM3lFWHJvd5Sv70wuHA94G5ScpzD2BLkkfGT0iunyMi6WND7WJ0FGdHdl06yvNckncIAG42vN8HWJVklLwKWNP2TZKWBk6kps1sGKUtYP4G9WlCk+fqncAUSR1PGpGmQurGPBxMMtrOTRqlf8T23yW9mdRxrP3SlTTU1KGy/PFkYeB6SRcz/TPVeBqyHxWCbV8u6T3A7yS9lebGxA4/A6aRfnR/yz+4JjaE6nUPGrBv1oZ1uRo40Pa1A3coB+EVpvZLzsl4PiuwfC66yfZzDa9XSnmOteJkiGsNRQnlibO9QNIdTg4B2L49z5nXZUtgVyovkQqb9VrHAnygx/NnsX0NgKT7bf8dIL8f5mgo639IHZbBjO3jPdOybylB/agQ7gGw/YCk9wHfI/lHN8b2j4BqL+p2Ses0EPFTSXPbfsL2/3YKJS1LCk5pws4MrYw+2lBWHX5f90BJawNHk5SngCUlbeFmnjOllOdYK04Ye+WJpJlsvwh8vlI2M83a6hLSPP0Fg8jft2mdatKkrW6XtCrwrlx0vu2rGlyr+qLec8C+ph2yy0lBj5cN3CHpCw1l1aFJO/1V0quANXPRxbbv6+qqpY0h/fYBPkTyP/9G5zMK16htlCwli/RCOpdsuANWAfbq8pqXASsMkH1ZQxlfYhDjHMlF8IcN5LwLWGqIfWuM0jPytQbHrg3cDvyV5Jb7b5rHbKwJzD5I+WTgsw3kLAjMOQrtMUf1eRiwb4MGcnYizY9/K3+uoYHPPbDRYPdHcvDYveE9rQAsPMS+V/XQVnMNUT6lgYxN8jN1NPCr/Ex9oqv6lH4YxuvTeWmQ5k9PGfjpUuZhuYH/Q5q3vQb4xSjUvbZHTylZ+YX0FqaPwOzKq4NBAuMGKyt0f0WUZxM5bVOeDa5V26OnlBxSfq2bgH/n7dV6+P1dXX1hkrz9ij9XNPDoKSWLFMR5PXBH3l4V+N8ur3kVsGhlexEaRuV3PuM991WSToKwA4EfDPLphrfb3hx42PY3SVHLS/Za0UEolWSuiaw5nYKHqjQNRupwqaRfSFo7f44gvfhGgyYePaXkHEGacngOwPbVdBmYRprXvqmzYftmevQ6GoYmHj2l5OxL6mg8AmD7StLIpRtEJf4gfy/5W+nQxKOnlKyDSTE3DwI4TYV1G8A3k6efInqQLu0afWNDcJ7bs/3XTlkOdFoy/4C74b/571OSXkNq6Nf2VNHBKRkdWFfWA5Je1zle0ifI9pcu2BbYDtiR9IP9G8nddjQo9UJoImdO2xdr+gSgPSlPXu7AfIbRU56lnqsmcp63/ajKJNI9EvinpJPz9keAX5QQ3AZs/2dAO3UbLPcnSWcBv8vbnyLFBjWmbxRCB0lTSXOHk0iRe/dL+qu7izg9LUe4fp9kVDIp+2VpxmOEsB3J1fP1ku4izTt+pstrTiJl2TwIXo507VLWSIzHS26iKs/x4NqcbmJmScuR7vMVRus62D4o/57fSWqrLW1fUaym48t/croJZyeDHUkBZo2x/ZXsbt1pp8NtnzzCaUMK66sPLye1+wLwzfy953lH0gtuvlGqc22jZAlZJI+e7+fvczEgsruLa15ExSBM8svuKqFZ3f/vWMohTZn8mRRDcBfwdwZJmlZT1lzAzAP+F8UNu+PYVnOS8lJdkj/fZhADeE1Za1WfTWAe4K1tbacmskixA78F7gXuIwWvLtTlNV9bbWOSUX9yV7JKN+54f0iG38VIkZZr5rJGCgH42HCfLupU0ihZRBZwXsE2v7JOWaFrFVGedeW0XXlSzqOnZzm5rf5c8H99BZWUDKR58a4dMCjg0VNCVm6n3xRsp0uBWSvbs5LyNTWW1U9G5Q7fIi308S/blyhlKL2loYwNh/l8uIs6lTRKlpJ1hdJqW5+rpsLosk5P5uhPACStzsv2l0YorUx3rqRr8/Yqkvbq7Lf9P2MpxykJ2ur5+5O2H29wO4Mxu+0nKvKfIPWqG5PTVFxJSomCpNWUsut2ZNdKP1FKTm6rp5Qyd5ZAzm+4LP9FupjmlvR2SdeTp2QkrSrppWk620eNpazcTovkqaISTLL9bEX+szSPs0iCClWoNTilqvh9Zfs24OOdbdXI4ml7y8LVKmmULCVrQZKRfN1KmUm52ZuyM/B7SXfn7cVIhq1uOAL4CilKHNtXSzqGNPUwHnIgK0/Sc/Vkp9B2N231pKQ3274celOevOzRMzXX50pJk8dRDsDTwDU5b1C1rZpn3oTbJO1IWk8EUir727qQ0/HoOSXX5SpJ3Xr0lJI1DfhHfq6q7TQwKLMO90vayPYp8NISuw90Iaf/FEINPgnUTev8P8ABth/J2wsAu9rea9gTX0lJo2QRWSWVXh6JvZ4UvCPSMocvRd9Keq/tc2qKK6XwSirhtirPUh49JT2DTs+fEmxDyhSwF6m9zwW27kaQy3n0lJJ1d/7MRLKN9MI2wG8ldRJm3kmzJJwvU2oea6J8aGYge8WxdDGHSVmjZBFZWc6pwP0ko9YfyctNjkKbN02l/TpeXr70E8CZXVyziJxRao9ZSOlU3siAJR6B9zaQ8wvg06QAruVICdsO66I+ReRU5M1Ksm29kcrc9ii0Y92o/BNIgWCX57rtBhzb5TWLycry5qVHu1RF1tyDyQK2qC1jtP5Zbf00fDldTSV3Pcnwdl3D6xUzShaWdRGpFzEpfz5LXn50FNr8igbHllR4JZVwG5VnEY+eUnKyrA+SIvunkqLh7wA+MJ5tRVmPniKygDVIDjDTeDmB5urj/kyNRgXa/Gn4cto9v0i2IiUR+zsNc6BkOSU9eorIGuzlD1w0Sm1e94dbROGVVJyddmmb8qSQR08pORV5NwLLVrZfR5pCHJe2oqBHT2FZVwPvqmy/k9FL9zJiO3U+M6INoXYWT9sHSLoaWJ80N76f7bO6uGZJo2QpWX+R9FXgWNL87KeA0yUtmOU91EXdesL2C9nIiu0nRzp+tOVUkO1fV7Z/I6npmrx18ciHvHSPT0maz/ajXV+skJwK99n+V2X7NlJPejQYsa3y/S0iaVZXPHG6ulhBWcDjts+vyP67pF492Iai1jMFfWhUlrQ8ySvhVbZXlrQKsJHtb0N9d8MOtv9Edscb5FoX2q6z8lJJo2QpWR1D5pcGlH8+yyuVBwfSkLgupRReSSXcOuWZKeXRU9Iz6DpJZ5AWjzfJieOSjktzl+0/FHWt4NMo59FTStbFkn5GSjfReaamdty3nb3QClHbW6DvFAJl3Q1HotaCKy7r0VNElu1hczI18QySNDvJJfCdpIf778Chtp/O12oS31BK4ZVUwm1VnqU8ekp6Bs1Oml9/T96+n/S/2JDu238o6o72S3r0lJK1Wv67z4Dyt5PaaV3K8Y+6ByrPMfUNki6xvaakK2y/KZddaXu1UbjW5bbfXOO4ZYBDSKH4Bi4Edrb97y6uWUzWCNepdW/52OOBx0kGNkirbS1gu1Rm0lZTR3mOFPTXbc85Bze9nvQs3NTtVEYpOTWuM2IcUOXY1wI7kLKlvtR5dRdLQ2Z586bTew4uLCprCPlb2D665rGl3OP7z6jMGLobUt9YWswoWVLWCNe5osGxr8i9PlhZTVlFPHpKySn1HJAydx5J6ok/TFr7+ETgIeCkLq9bxKOnlJxSbVV9hkhJ39YhjTjeA7yni2sW8+gpKatgO13Ry/nTnTca//Tx/FDQ3bCbf8QQxxXz6Ckpa4TrNHkgjwLWqmy/le4X+yii8MZKcTZ5DvKxpwGLVbYX60EhFPHoKSVnFNqqyP+Lgh49JWUVbKee3eM7n76yISilXd7W9vqS5iItHNHTkE7S0sBytv+stDD3pIrMutGAJY2SbTRwvhXYXNIdeXsp4AZJ16QqeZUGskp59LTOMygz2XY1svxeXl5fuSmlPHpa5RlU4RBJ+5ASVT7zkoDmBteSHj1j5R3UpJ1+A5wr6ch83udJy2k2ph9tCOfZLmKQkfRFUqj8grZfp5Tf/TDb6zWUM9z8vm3XNkqWlDXCdU5yTWNwVprDVer2Btfdn7TaVlXhzQb8NMuqpfBKyal5rSb2lp+QooE73iWbkhIx7tDFdQ8FlmZ6j56byEZE17RLlJJT81pXONv2ahz7XVKn61bgxVzspr9vSQeTgu+qHj2dabtGCqakrBGuU7ud8vHv52X3+LPdnXt8XyqEH5B+cD27G0q6kpT0659+2UB9je03lqntS9dpkuuniKyRPIO6uO4CpOVFq8a/xj+OUgpvrBRnvlZt5ZmP/xjwrrz5N3e5mEnuEQ6FbX9+LOXUvNbXXD9j7Y3AKu7RwC3pL8PsbqRgSsoa4To/sV17RDtgJmNO0pobjUcu/agQBnu4u3qoJf3T9ls72lrSJNLcepMpkDrXqd3DLCWrpGeQpP2AKaSeXOeBKvbjGHCtIspzPD2DxoomHj2l5JT0DJJ0HLCDp18vuDhNPHpKySrpGVRqJgP6UCGURNIBpGmHzUkP+f8Drrf99cLXaTQ8LCFL0lW2Vx2prOY1bwLe2GtPrua1iijPOnIqnYtFSf7h5+XtdYCpTUYFFZkfA76XZSp/bHveprJqXGvM2qpy7FWkZHnX8PI0D66sdd7gulNJSfIuYXobQldup8NcZzw6ZK/4nXZbj5IzGX1jVJa0u1OqiR8ziEHG3UVdfpWUx+gaUlDSGbaP6K2mg1JSK9eVdYWktWxfBCDprTQIYBnAtcD8jJ4hskqp9adHlOMcBCjpNGDFjjFY0mJkW0QXHABsaLur9XMbMmZtVeFp2z8qdN2BQVujxXisaT6zpNlsPwOQHVa6XYf8GdvPKqfkzjMZXb1T+kYhAHuQfmy3kow8JfgMKbXtS0pA0odtn1ZI/nhS0jPouyQFcy2j2JPriB0HOSU9g+4dI2UA49NWpTyDuhpVdMl4dMiKeQYBf5X0NWAOSe8lzWSc2o2gflII92bDypakIX0JfgzsKmmzyo/4WyRf8pJMGwdZ7y94zaNJ0yDTTRP0EVMlncX0nkHDGReH49I8N/4Hpn9hjoY9YjxGCG8keQatS8UziC5SMWR3zs4LdlbSOhJPjsL02piPEFwucSakzvAXqMxkAD/vRlA/KYRDSUnoliEtOt1BdJ9v5t+kKaMTJO3rtDxn44dnJI+ehh4qRWTZvr2UZxDwQMFpgpGYNtZybG8/wDPo8G49g0gLojwFbFC9BGVz/HSondm3oJyPAsuUsCfZni5XkKSPkObKS9PtVGmvsm4grVb3Z0lzSpqnqWeQpJlIgXErk/K49UTfGZUlHWp720KyLrf9ZkkLk3qHVwEbNPUyKuzRU0RWSc8gSQeRerun0OU0QSmPnonuGdSEUh49E8kzSNJFttdqeE5Jj54isop6Bkm/Ja0ed8eIB48kq98UQkkknW77Q/n7TKRpkV1tz9RQTkmPniKySnoGDeGb3dS/u4hHT1s9g0bD6aGUR09bPYMGKPeZSHmE3uN6Keerckp69BSRVdIzSNJ5wJrAxUwfe9W4zftpyqg4HWWQv79ISqv9lS5ElfToKSWrmGeQ7Z5tNqU8elrsGTSbpDVJo8xnKTNvXcqjp62eQRtWvj9PmubbuAs5JT16Sskq5hkEfLPL815BKIRBkPRD2ztLOpXBe3NNNW9Jj55Ssop5Bkl6FfA/wGtsf0DSisDbbP+iqSzKefS0zTNoPlLa8jeQlMIFJEV+obtPo1HKo6eVnkEut45ISY+eUrJ69gzK9sRtgGVJo7tf2H6+i7q8LDOmjF6JpNVtXybpPYPt72JIXjLXTxFZkq4jLSJUYprgTFJq56/bXjX3dq7ocvhbJNdPKTlZ1iHAqyngGaS07sAapOmst+XPI7ZX7EJWqVw/ReRkWT17Bg01rdahy+m1Irl+SslSGhp8geRcIOAs4Odu8ELO9prngPOBDwC3296paV2mkxkKoR4djxzbV/dyPr179BSRJemvtgdVeA1kTLL9vAovSqRyuX5GM2eQ3V06lPlISuAd+e/8wDXd9IZVLtdPETlDyP4I8BbbX2twzhaVzW8yYBrKXaSZUKFcPyVkDfAM6pqqzSF3wi7uxi5SJaaMhiEbyDYitdOVwP35RfrlhnIG9eihO9/sUrIuyz3Drj2DSEasNwNPSlqoUx9JawG9LPx+EgXcMAvK6XnqQtLhwEokD7F/kqaMDrLdSxDlVZSxA5WS8wps/0EpXXuTc1564UvauRsFUKXq0UNa62Fx4DCgG4+enmXZflHSVZKW6tEz6LmKzOc79oheCIUwPPPZfkzSF4Ajbe+jFEzSlE2A1xXqgZWS1fGUqLrwNVUsnSfwyyTF8jpJ/wAWIa1U15gSHj2l5BT2DFqKZHy8hbRw052kPFm98CrgRkm9evSUkjOUZ1Av0xAlpjC2I3v0ANi+RdKi4yxrMeA6Sb14Bq0q6bH8XSR7xGN0+ZuBUAgjMSl7p2wC9JLQrmSunyKySngGAYtI6oyWTiZFSIr0UlmftJJTU0rl+mmVZ5Dt9+d545VI9oNdgZUlPUQyLHfjnVPKo6eNnkElKenRU0pWz55BtmfuVcZAQiEMz7dIxp6/275EaYH7W7qQUzLXTxFZhTyDZgbm5pUvyjmb1GUApXL9tM4zKBsMr5X0CGlK7VHgw6QeZ+OXcimPnrZ5Bg0wTM85oBfcTc+3Z4+eUrJGwzOoJGFU7gHVzBNf2KOniKwSnkEqmDa4IrOIR0/bPIMk7ZjPfwdp7vcfwIX57zVOcS5N61Uk109bPYNKUcKjp5Ss0fAMKkmMEHrjk6Qe+0iUzPXTk6yOZxCwsO3jJe0JLxmlXmgqrtt6DEOpXD8lcwbNkeXNlz93kxRyEyYDJwC7ePr4iK5xoVw/heRU84e9wjNovFDBXD+FZK1Y8Qz6BckxozWEQuiNui/EEh49pWSV9Axq7KUxEiWmHErJKekZ1NQzrRu68egpJae0Z1ApCnr0lJJV3DOoJKEQeqPukLOER08pWcU8g7qZRx+yUoU8eiaAZ1AxSnn0tNQzqCQlPHpKySruGVSSUAi9UTf3ean1GUrIGg3PoBKU8uhpu2dQSUp59LTRM6gkxXL99CprNDyDShIKoTdq5Ykv5NFTStZoeAaVoJRHT6s9g0rSsum10p5BPVPSo6ft3kGlCC+jYZC0PGnhnVfZXlnSKsBGtr/dUE7JXD89yRoNz6CSlPDoKSVnNDyDSlDKo6fNnkElKOnR03bvoFLECGF4jiClu/4ZgO2rJR0D1FIIJT16CspqlxXrlZTw6CklZzKFPYMKUcqjp5WeQQUp6dHTau+gUoRCGJ45bV88wBOgyTCxpEdPKVnFPYNKUMqjZ6J5BnVDKY+etnoGFaSkR0+rvYNKEQpheB6Q9Dpefvl+AmjSUyyZ66eIrJKeQYUp5dHTas+gUaDUnG8/zh2X9OhptXdQKcKGMAw5VcXhpHnkh4F/A59x/TUH7gQOypszkV5UHY+eF2wfNNS5oymrrQzw6Hk7sDLQ2KOnlJyJQCmbUNttS8HYECOEIZA0M7Ct7fUlzQXM5Ob500t69LTVO6gYpTx62uwZVIJSHj1t9AwKxpcYIQyDpPPcxapRlfOL9br6vQdXyqOnrZ5BQTARiBHC8Fwh6RRSvEE1KrFuPpySlqf+tGK9zGTKePSUkhMEMxwxQhgG9bh0oqQFSxlxS8oKgiAYjFAIQRAEARBTRoNSOEFaEATBhCBGCIMg6UHbC0nameRuOh19GMATBEEQI4QhuFfS0sCWQLFMpUEQBG0mFMLgHAr8CViG6fO9iDSFtMx4VCoIgmA0iSmjYZB0qO1tx7seQRAEY0EohCAIggBIOXGCIAiCIBRCEARBkAiFEARBEAChEIIgCILM/wf4FIkZGIt9cgAAAABJRU5ErkJggg=="
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Since there are a lot of missing data in precipitation aspect, we ignore this factor. In addition, to extract as most and relative information as possible, we choose to focus on indices 7 days prior to the wildfire."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "source": [
                "select_col = [raw['fire_size'], raw['fire_size_class'], raw['Temp_pre_7'], \n",
                "              raw['Wind_pre_7'], raw['Hum_pre_7']]\n",
                "\n",
                "# drop all rows with NaN\n",
                "df = pd.concat(select_col, axis=1).dropna().reset_index()\n",
                "\n",
                "# view current data set\n",
                "df"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "      index  fire_size fire_size_class  Temp_pre_7  Wind_pre_7  Hum_pre_7\n",
                            "0        78      450.0               E   28.499405    2.769643  49.000000\n",
                            "1        88        3.0               B   19.495294    3.401190  64.461538\n",
                            "2       192        1.0               B   15.781065    1.110355  58.560897\n",
                            "3       267        1.0               B    4.586826    0.650699  63.141717\n",
                            "4       274        1.3               B   17.417453    2.402830  50.336788\n",
                            "...     ...        ...             ...         ...         ...        ...\n",
                            "2457  55197     6533.0               G    4.676829    2.454878  42.447154\n",
                            "2458  55198     8051.0               G   26.402381    3.169643  45.226190\n",
                            "2459  55199    10570.0               G   21.403933    2.075000  33.509202\n",
                            "2460  55364     5702.0               G   28.166667    2.667722  44.443975\n",
                            "2461  55366    76067.0               G   21.963095    1.036905  37.178571\n",
                            "\n",
                            "[2462 rows x 6 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>index</th>\n",
                            "      <th>fire_size</th>\n",
                            "      <th>fire_size_class</th>\n",
                            "      <th>Temp_pre_7</th>\n",
                            "      <th>Wind_pre_7</th>\n",
                            "      <th>Hum_pre_7</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>78</td>\n",
                            "      <td>450.0</td>\n",
                            "      <td>E</td>\n",
                            "      <td>28.499405</td>\n",
                            "      <td>2.769643</td>\n",
                            "      <td>49.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>88</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>19.495294</td>\n",
                            "      <td>3.401190</td>\n",
                            "      <td>64.461538</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>192</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>15.781065</td>\n",
                            "      <td>1.110355</td>\n",
                            "      <td>58.560897</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>267</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>4.586826</td>\n",
                            "      <td>0.650699</td>\n",
                            "      <td>63.141717</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>274</td>\n",
                            "      <td>1.3</td>\n",
                            "      <td>B</td>\n",
                            "      <td>17.417453</td>\n",
                            "      <td>2.402830</td>\n",
                            "      <td>50.336788</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2457</th>\n",
                            "      <td>55197</td>\n",
                            "      <td>6533.0</td>\n",
                            "      <td>G</td>\n",
                            "      <td>4.676829</td>\n",
                            "      <td>2.454878</td>\n",
                            "      <td>42.447154</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2458</th>\n",
                            "      <td>55198</td>\n",
                            "      <td>8051.0</td>\n",
                            "      <td>G</td>\n",
                            "      <td>26.402381</td>\n",
                            "      <td>3.169643</td>\n",
                            "      <td>45.226190</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2459</th>\n",
                            "      <td>55199</td>\n",
                            "      <td>10570.0</td>\n",
                            "      <td>G</td>\n",
                            "      <td>21.403933</td>\n",
                            "      <td>2.075000</td>\n",
                            "      <td>33.509202</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2460</th>\n",
                            "      <td>55364</td>\n",
                            "      <td>5702.0</td>\n",
                            "      <td>G</td>\n",
                            "      <td>28.166667</td>\n",
                            "      <td>2.667722</td>\n",
                            "      <td>44.443975</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2461</th>\n",
                            "      <td>55366</td>\n",
                            "      <td>76067.0</td>\n",
                            "      <td>G</td>\n",
                            "      <td>21.963095</td>\n",
                            "      <td>1.036905</td>\n",
                            "      <td>37.178571</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>2462 rows × 6 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 70
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now our data set is cleaned. The next step is to choose the algorithms. Notice that the range of the numerical indicator of the magnitude of the wildfires `fire_size` is **very large**: [1.0, 760671.0]. However, our variance of climate indicators are comparatively **very small**. Thus, to determine the numerical magnitude (`fire_size`) through regression is not a wise choice. Otherwise, we need to \"magnify\" the very small amount of changes in climate indicators to describe the variations in `fire_size`.<br>\n",
                "\n",
                "Hence, we turn to classifications. Here, we do three classification models: **RidgeClassifier, RandomForestClassifier, KNeighborsClassifier.** <br>"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Train the Models\n",
                "\n",
                "Here is the most important rule in all of machine learning: **You need to set aside some data that you never look at while training to assess how your model will do in the future.**\n",
                "\n",
                "Because this is so important, `sklearn` provides a function called `train_test_split` to break your dataset up (randomly) into a training set and test set. The cell below shows how to call it."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# select our features (factors) and labels (the one to be predicted)\n",
                "features = df.loc[:, 'Temp_pre_7':'Hum_pre_7']\n",
                "labels = df['fire_size_class']\n",
                "\n",
                "# take 0.8 of our data to train the model, 0.2 to test\n",
                "features_train, features_test, labels_train, labels_test = \\\n",
                "    train_test_split(features, labels, test_size=0.2)\n",
                "\n",
                "# Print the number of training examples and the number of testing examples\n",
                "print(len(features_train), len(features_test))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "1969 493\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **KNeighborsClassifier**\n",
                "Now we first look at KNeiborsClassifier.\n",
                "> "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "source": [
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "\n",
                "# Create KNN classifier \n",
                "knn = KNeighborsClassifier(n_neighbors = 3)\n",
                "\n",
                "# Fit the classifier to the data\n",
                "knn.fit(features_train,labels_train)\n",
                "\n",
                "#check accuracy of our model on the test data\n",
                "knn.score(features_test, labels_test)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0.5963488843813387"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 72
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Our accuracy is about 0.60, which is not very good. Let's play with the parameter `n_neighbors` to see if there will be any changes."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "source": [
                "# define the function that fit the model and test the accuracy\n",
                "def kneibor(num):\n",
                "    knn = KNeighborsClassifier(n_neighbors = num)\n",
                "    knn.fit(features_train,labels_train)\n",
                "    return knn.score(features_test, labels_test)\n",
                "\n",
                "\n",
                "# test serveral number of neighbors\n",
                "scores = []\n",
                "for i in range(1, 50):\n",
                "    scores.append(kneibor(i))\n",
                "\n",
                "## plot the scores v.s. number of neighbors\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# plot the plain graph\n",
                "plt.plot(range(1, 50), scores)\n",
                "\n",
                "plt.grid()  # add grid\n",
                "plt.xlabel(\"Number of Neighbors\")   # add xlabel\n",
                "plt.ylabel(\"Scores\")    # add ylabel\n",
                "\n",
                "# print the highest score\n",
                "max(scores)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0.6531440162271805"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 73
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ],
                        "image/png": "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"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "From the above graph, we notice that our model is improving as `n_neighbors` increases. Then, it would be very nice if we play with the parameters when we do machine learning, which is called tuning. The accuracy score reaches the highest and stabilize for `n_neighbors >= 40` at around 0.65.<br> \n",
                "\n",
                "Apart from the parameter, is there any other way to improve our model? Of course, we will use **k-Fold Cross-Validation** to see if any improvement."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "source": [
                "from sklearn.model_selection import cross_val_score\n",
                "\n",
                "#create a new KNN model\n",
                "knn_cv = KNeighborsClassifier(n_neighbors=40)\n",
                "\n",
                "#train model with cv of 5 \n",
                "cv_scores = cross_val_score(knn_cv, features, labels, cv=5)\n",
                "\n",
                "#print each cv score (accuracy) and average them\n",
                "print(cv_scores)\n",
                "print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[0.65858586 0.65991903 0.66191446 0.66395112 0.66395112]\n",
                        "cv_scores mean:0.6616643175073875\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "With Cross-Validation, we find our average score higher than the highest score of KNeibor it self. This has shown that **k-Fold Cross-Validation** is an improvement.\n",
                "\n",
                "Wait, the parameter `n_neighbors` we used is 40, unchanged for 5 cross validations. Don't forget our first method to \"tune\" the model is to play with `n_neighbors`. Now, we do it again, and it is called **Hyper Tuning**."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# create a new KNeighborClassifier model\n",
                "knn_new = KNeighborsClassifier()\n",
                "\n",
                "# create a dictionary of values to test for n_neighbors\n",
                "param_grid = {'n_neighbors': np.arange(1, 50)}\n",
                "# We choose 5 to 50 because our previous trials show the trend that our accuracy will increase as n_neighbors grows.\n",
                "\n",
                "# use gridsearch to test all values for n_neighbors\n",
                "knn_gscv = GridSearchCV(knn_new, param_grid, cv=5)\n",
                "\n",
                "# train the model\n",
                "knn_gscv.fit(features, labels)\n",
                "\n",
                "# find the top performing n_neighbors value\n",
                "knn_gscv.best_params_"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'n_neighbors': 34}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 75
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Great, we obtain a different value of `n_neighbors = 34` than `40`. What about its performance?  "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "source": [
                "# find the average accuracy for the top performing value of n_neighbors\n",
                "knn_gscv.best_score_"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0.6620633631194152"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 76
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Well, well, well. The overall performance seems unchanged, only merely 0.01 improvement. So, we might ask: whether or not KNeighborClassifer is suitable for this data set? Let's try another algorithm. <br>\n",
                "\n",
                "### **RandomForestClassifier**"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "source": [
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "# import the library to compute the accuracy (another way)\n",
                "from sklearn import metrics\n",
                "\n",
                "# initialize the model\n",
                "clf = RandomForestClassifier(n_estimators=100)\n",
                "\n",
                "# train the model\n",
                "clf.fit(features_train, labels_train)\n",
                "\n",
                "# use the model to predict based on features_test\n",
                "pred = clf.predict(features_test)\n",
                "\n",
                "# compute the accuracy\n",
                "print(\"Test Score\", metrics.accuracy_score(labels_test, pred))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Test Score 0.6531440162271805\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Our first trail with default settings gives accuracy of 0.64. It is more all less the same as kNeighborClassifier. Lets' try to see how can we tune the model. If we take a closer look at the initilizer of the model, we will see"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "source": [
                "print(clf.get_params())"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Yes, there are a huge amount of paraemeters we could play with. In this example, we will focuse on these ones:\n",
                "- n_estimators: number of trees in the foreset,\n",
                "- max_features: max number of features considered for splitting a node,\n",
                "- max_depth: max number of levels in each decision tree,\n",
                "- min_samples_split: min number of data points placed in a node before the node is split,\n",
                "- min_samples_leaf: min number of data points allowed in a leaf node,\n",
                "- bootstrap: method for sampling data points (with or without replacement). <br>\n",
                "\n",
                "But, there are still so many of them. Don't worry! Don't forget something called **Cross Validation** we used in previous cells. We will use this fantasitic tool to **hyper tune** the model again. \n",
                "\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "source": [
                "from sklearn.model_selection import RandomizedSearchCV\n",
                "\n",
                "# number of trees in random forest\n",
                "n_estimators = range(100, 2001, 10)\n",
                "\n",
                "# number of features to consider at every split\n",
                "max_features = ['auto', 'sqrt']\n",
                "\n",
                "# maximum number of levels in tree\n",
                "max_depth = range(10, 111, 10)\n",
                "\n",
                "# minimum number of samples required to split a node\n",
                "min_samples_split = [2, 5, 10, 20]\n",
                "\n",
                "# minimum number of samples required at each leaf node\n",
                "min_samples_leaf = [1, 2, 4, 8]\n",
                "\n",
                "# method of selecting samples for training each tree\n",
                "bootstrap = [True, False]\n",
                "\n",
                "# combine the above settings into the one so called the random grid\n",
                "random_grid = {'n_estimators': n_estimators,\n",
                "               'max_features': max_features,\n",
                "               'max_depth': max_depth,\n",
                "               'min_samples_split': min_samples_split,\n",
                "               'min_samples_leaf': min_samples_leaf,\n",
                "               'bootstrap': bootstrap}\n",
                "\n",
                "print(random_grid)\n",
                "\n",
                "# Note: the official website of RandomForest Classifier provdies detailed explanation on the funciton of each parameter: \n",
                "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html "
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{'n_estimators': range(100, 2001, 10), 'max_features': ['auto', 'sqrt'], 'max_depth': range(10, 111, 10), 'min_samples_split': [2, 5, 10, 20], 'min_samples_leaf': [1, 2, 4, 8], 'bootstrap': [True, False]}\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Per iteration, the algorithm will choose a difference combination of these paremeters. To sum up, there are 19 * 2 * 10 * 4 * 4 * 2 = 12,160 settings! However, the benefit of a random search is that we are not trying every combination, but selecting at random to sample a wide range of values. Let's do it!"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "source": [
                "# initilize the model to be tuned\n",
                "rf = RandomForestClassifier()\n",
                "\n",
                "# random search of parameters, using 5 fold cross validation, \n",
                "# search across 100 different combinations, and use all available cores\n",
                "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
                "                               n_iter = 100, cv = 3, verbose=2, n_jobs = -1)\n",
                "\n",
                "# train the random search model\n",
                "rf_random.fit(features_train, labels_train)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
                        "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.1s\n",
                        "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   53.5s\n",
                        "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.9min finished\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
                            "                   estimator=RandomForestClassifier(bootstrap=True,\n",
                            "                                                    class_weight=None,\n",
                            "                                                    criterion='gini',\n",
                            "                                                    max_depth=None,\n",
                            "                                                    max_features='auto',\n",
                            "                                                    max_leaf_nodes=None,\n",
                            "                                                    min_impurity_decrease=0.0,\n",
                            "                                                    min_impurity_split=None,\n",
                            "                                                    min_samples_leaf=1,\n",
                            "                                                    min_samples_split=2,\n",
                            "                                                    min_weight_fraction_leaf=0.0,\n",
                            "                                                    n_estimators='warn',\n",
                            "                                                    n_jobs=None,\n",
                            "                                                    oob_sc...\n",
                            "                                                    warm_start=False),\n",
                            "                   iid='warn', n_iter=100, n_jobs=-1,\n",
                            "                   param_distributions={'bootstrap': [True, False],\n",
                            "                                        'max_depth': range(10, 111, 10),\n",
                            "                                        'max_features': ['auto', 'sqrt'],\n",
                            "                                        'min_samples_leaf': [1, 2, 4, 8],\n",
                            "                                        'min_samples_split': [2, 5, 10, 20],\n",
                            "                                        'n_estimators': range(100, 2001, 10)},\n",
                            "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
                            "                   return_train_score=False, scoring=None, verbose=2)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 80
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Wow, that indeed takes some time to do such big amount of work. <br>\n",
                "\n",
                "Here we will introduce two most important parameters in RandomizedSearchCV:\n",
                "- `n_iter`: controls the number of different combinations to try (we used 100)\n",
                "- `cv`: the number of folds to use for cross validation (we used 3) <br>\n",
                "\n",
                "As we see, the more wider the search tree was, the more time it will take to complete the task. Machine learning is a field of trade-offs, and performance vs time is one of the most fundamental. <br>\n",
                "\n",
                "Lets' see what we got here! "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "source": [
                "# show the best choice\n",
                "rf_random.best_params_"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'n_estimators': 520,\n",
                            " 'min_samples_split': 5,\n",
                            " 'min_samples_leaf': 4,\n",
                            " 'max_features': 'sqrt',\n",
                            " 'max_depth': 20,\n",
                            " 'bootstrap': True}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 81
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "source": [
                "# show the best accuracy\n",
                "rf_random.best_score_"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0.6714068054850177"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 82
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now, we obtain our best RandomForest Classifier of accuracy = 0.67 with a 0.03 increase. But, don't forget that is our score on the training data. How about our testing data?"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "source": [
                "# choose the optimized model from above trails\n",
                "rf_opt = rf_random.best_estimator_\n",
                "\n",
                "# accuracy on test data\n",
                "print(\"Test Score:\", metrics.accuracy_score(labels_test, rf_opt.predict(features_test)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Test Score: 0.6511156186612576\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Humm, it seems nonthing has changed. It is likely that our algorithm is not an expert dealing with our data. What about another algorithm? <br>\n",
                "\n",
                "### **RidgeClassifier**\n",
                "\n",
                "Similarly, we will first do the very basic example."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "source": [
                "from sklearn.linear_model import RidgeClassifier\n",
                "\n",
                "# initialize the model\n",
                "rc = RidgeClassifier()\n",
                "\n",
                "# preview the parameters of the model\n",
                "print(rc)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
                        "                max_iter=None, normalize=False, random_state=None,\n",
                        "                solver='auto', tol=0.001)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "source": [
                "# train the model\n",
                "rc.fit(features_train, labels_train)\n",
                "\n",
                "# accuracy based on trainning data\n",
                "score = rc.score(features_train, labels_train)\n",
                "print(\"Train Score: \", score)\n",
                "\n",
                "# cross-validated accuracy based on trainning data\n",
                "cv_scores = cross_val_score(rc, features_train, labels_train, cv=10)\n",
                "print(\"CV average score: %.2f\" % cv_scores.mean())\n",
                "\n",
                "# prediction accuracy\n",
                "print(\"Test Score: \", rc.score(features_test, labels_test))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Train Score:  0.664804469273743\n",
                        "CV average score: 0.66\n",
                        "Test Score:  0.6511156186612576\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Hold on before tuning the model. It looks like quite coincident that all our three models gives predictions of around 0.65 accuracy. Apart form the cold numbers, do we have a **detailed report** about what is going on inside our test? Certainly!"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "source": [
                "# output the test report\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "print(classification_report(labels_test, pred))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           B       0.68      0.94      0.79       321\n",
                        "           C       0.21      0.04      0.07        73\n",
                        "           D       0.00      0.00      0.00        14\n",
                        "           E       0.00      0.00      0.00         9\n",
                        "           F       0.33      0.12      0.17        26\n",
                        "           G       0.58      0.30      0.39        50\n",
                        "\n",
                        "    accuracy                           0.65       493\n",
                        "   macro avg       0.30      0.23      0.24       493\n",
                        "weighted avg       0.55      0.65      0.57       493\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "In the matrix, we find all possible `labels` in the left column and some confusing terms in the top row. What are they?\n",
                "- **Precision**: the number/ratio of positive class predictions that actually belong to the positive class. (correct predictions);\n",
                "- **Recall**: the number/raio of positive class predictions made out of all positive examples in the dataset. (eg. total 'B' predictions);\n",
                "- **F1-score**: the single score that balances both the concerns of precision and recall in one number;\n",
                "- **Support**: the number of certain cases in the prediction. <br>\n",
                "\n",
                "From the report, we generally find the detailed problem of our model: insufficient/biased training data for classification. It is understandable that the maginitude of wildfires depends on not only temperature, wind, or humidity, but also geographical factors: the shape of the mountain, the vegetation of the region, and the human resources engaged in controlling the fire. This implies the importance of the comprehensiveness of data sets and illunimates what can we do to prove our models."
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.5 64-bit ('cse163': conda)"
        },
        "interpreter": {
            "hash": "eb0ef345f182d5544068c9b359f219ebd829ef39d26f94d6f8ac4d1b7a14f6eb"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
